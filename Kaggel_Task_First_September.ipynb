{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frey87/FreeCodeCamp_Projects_aka_Tasks/blob/main/Kaggel_Task_First_September.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNPN1AUdXe43"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# deep learning libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import applications\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# datasets\n",
        "labels = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ukraine-ml-bootcamp-2023/train.csv')\n",
        "sample = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ukraine-ml-bootcamp-2023/sample_submission.csv')\n",
        "\n",
        "# folders paths\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/ukraine-ml-bootcamp-2023/images/train_images'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/ukraine-ml-bootcamp-2023/images/test_images'"
      ],
      "metadata": {
        "id": "khHALf_2XjD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.head()"
      ],
      "metadata": {
        "id": "4x_AzBiXX2_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data agumentation and pre-processing using tensorflow\n",
        "gen = ImageDataGenerator(\n",
        "\t\t\t\trescale=1./255.,\n",
        "\t\t\t\thorizontal_flip = True,\n",
        "\t\t\t\tvalidation_split=0.2 # training: 80% data, validation: 20% data\n",
        "\t\t\t\t)\n",
        "\n",
        "train_generator = gen.flow_from_dataframe(\n",
        "\tlabels, # dataframe\n",
        "\tdirectory = train_path, # images data path / folder in which images are there\n",
        "\tx_col = 'image_id',\n",
        "\ty_col = 'class_6',\n",
        "\tsubset=\"training\",\n",
        "\tcolor_mode=\"rgb\",\n",
        "\ttarget_size = (331,331), # image height , image width 215, 300\n",
        "\tclass_mode=\"categorical\",\n",
        "\tbatch_size=32,\n",
        "\tshuffle=True,\n",
        "\tseed=42,\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = gen.flow_from_dataframe(\n",
        "\tlabels, # dataframe\n",
        "\tdirectory = train_path, # images data path / folder in which images are there\n",
        "\tx_col = 'image_id',\n",
        "\ty_col = 'class_6',\n",
        "\tsubset=\"validation\",\n",
        "\tcolor_mode=\"rgb\",\n",
        "\ttarget_size = (331,331), # image height , image width 215, 300\n",
        "\tclass_mode=\"categorical\",\n",
        "\tbatch_size=32,\n",
        "\tshuffle=True,\n",
        "\tseed=42,\n",
        ")"
      ],
      "metadata": {
        "id": "7W1F8xjXX-Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = next(train_generator)\n",
        "x.shape # input shape of one record is (331,331,3) , 32: is the batch size"
      ],
      "metadata": {
        "id": "Di6yCECWX_j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = train_generator.class_indices\n",
        "class_names = list(a.keys()) # storing class names in a list\n",
        "\n",
        "\n",
        "def plot_images(img, labels):\n",
        "\tplt.figure(figsize=[15, 10])\n",
        "\tfor i in range(25):\n",
        "\t\tplt.subplot(5, 5, i+1)\n",
        "\t\tplt.imshow(img[i])\n",
        "\t\tplt.title(class_names[np.argmax(labels[i])])\n",
        "\t\tplt.axis('off')\n",
        "\n",
        "plot_images(x,y)"
      ],
      "metadata": {
        "id": "rR6PK6YDYCiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the InceptionResNetV2 architecture with imagenet weights as base\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "\t\t\t\t\tinclude_top=False,\n",
        "\t\t\t\t\tweights='imagenet',\n",
        "\t\t\t\t\tinput_shape=(331,331,3) # 215, 300, 3\n",
        "\t\t\t\t\t)\n",
        "\n",
        "base_model.trainable=False\n",
        "# For freezing the layer we make use of layer.trainable = False\n",
        "# means that its internal state will not change during training.\n",
        "# model's trainable weights will not be updated during fit(),\n",
        "# and also its state updates will not run.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\tbase_model,\n",
        "\t\ttf.keras.layers.BatchNormalization(renorm=True),\n",
        "\t\ttf.keras.layers.GlobalAveragePooling2D(),\n",
        "\t\ttf.keras.layers.Dense(512, activation='relu'),\n",
        "\t\ttf.keras.layers.Dense(256, activation='relu'),\n",
        "\t\ttf.keras.layers.Dropout(0.5),\n",
        "\t\ttf.keras.layers.Dense(128, activation='relu'),\n",
        "\t\ttf.keras.layers.Dense(120, activation='softmax')\n",
        "\t])"
      ],
      "metadata": {
        "id": "YrKIEkusYE9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the InceptionResNetV2 architecture with imagenet weights as base\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "\t\t\t\t\tinclude_top=False,\n",
        "\t\t\t\t\tweights='imagenet',\n",
        "\t\t\t\t\tinput_shape=(331,331,3) # 215, 300, 3\n",
        "\t\t\t\t\t)\n",
        "\n",
        "base_model.trainable=False\n",
        "# For freezing the layer we make use of layer.trainable = False\n",
        "# means that its internal state will not change during training.\n",
        "# model's trainable weights will not be updated during fit(),\n",
        "# and also its state updates will not run.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\tbase_model,\n",
        "\t\ttf.keras.layers.BatchNormalization(renorm=True),\n",
        "\t\ttf.keras.layers.GlobalAveragePooling2D(),\n",
        "\t\ttf.keras.layers.Dense(512, activation='relu'),\n",
        "\t\ttf.keras.layers.Dense(256, activation='relu'),\n",
        "\t\ttf.keras.layers.Dropout(0.5),\n",
        "\t\ttf.keras.layers.Dense(128, activation='relu'),\n",
        "\t\ttf.keras.layers.Dense(120, activation='softmax')\n",
        "\t])"
      ],
      "metadata": {
        "id": "xA0f_a8OYJXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# categorical cross entropy is taken since its used as a loss function for\n",
        "# multi-class classification problems where there are two or more output labels.\n",
        "# using Adam optimizer for better performance\n",
        "# other optimizers such as sgd can also be used depending upon the model"
      ],
      "metadata": {
        "id": "-3Ju46IYYLGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early = tf.keras.callbacks.EarlyStopping( patience=10,\n",
        "\t\t\t\t\t\t\t\t\t\tmin_delta=0.001,\n",
        "\t\t\t\t\t\t\t\t\t\trestore_best_weights=True)\n",
        "# early stopping call back"
      ],
      "metadata": {
        "id": "-mSHMAdIYO-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n",
        "\n",
        "# fit model\n",
        "history = model.fit(train_generator,\n",
        "\t\t\t\t\tsteps_per_epoch=STEP_SIZE_TRAIN,\n",
        "\t\t\t\t\tvalidation_data=validation_generator,\n",
        "\t\t\t\t\tvalidation_steps=STEP_SIZE_VALID,\n",
        "\t\t\t\t\tepochs=25,\n",
        "\t\t\t\t\tcallbacks=[early]"
      ],
      "metadata": {
        "id": "R_6qc7odYSlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Model.h5\")"
      ],
      "metadata": {
        "id": "4hvptOAeYZJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "# plot results\n",
        "# accuracy\n",
        "plt.figure(figsize=(10, 16))\n",
        "plt.rcParams['figure.figsize'] = [16, 9]\n",
        "plt.rcParams['font.size'] = 14\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'\\nTraining and Validation Accuracy. \\nTrain Accuracy:\n",
        "\t\t{str(acc[-1])}\\nValidation Accuracy: {str(val_acc[-1])}')\n"
      ],
      "metadata": {
        "id": "1HCch3bHYeEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title(f'Training and Validation Loss. \\nTrain Loss:\n",
        "\t\t{str(loss[-1])}\\nValidation Loss: {str(val_loss[-1])}')\n",
        "plt.xlabel('epoch')\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xVfCbYdjYjFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score = model.evaluate(validation_generator)\n",
        "print(accuracy_score)\n",
        "print(\"Accuracy: {:.4f}%\".format(accuracy_score[1] * 100))\n",
        "\n",
        "print(\"Loss: \",accuracy_score[0])\n"
      ],
      "metadata": {
        "id": "bgSCqegYYmtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = test_path+\"/000621fb3cbb32d8935728e48679680e.jpg\"\n",
        "\n",
        "img = cv2.imread(test_img_path)\n",
        "resized_img = cv2.resize(img, (331, 331)).reshape(-1, 331, 331, 3)/255 ## 215, 300, 3\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.title(\"TEST IMAGE\")\n",
        "plt.imshow(resized_img[0])\n"
      ],
      "metadata": {
        "id": "9E3EivLsYsUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for image in sample.id:\n",
        "\timg = tf.keras.preprocessing.image.load_img(test_path +'/'+ image)\n",
        "\timg = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\timg = tf.keras.preprocessing.image.smart_resize(img, (331, 331)) # 215, 300, 3\n",
        "\timg = tf.reshape(img, (-1, 331, 331, 3)) # 215, 300, 3\n",
        "\tprediction = model.predict(img/255)\n",
        "\tpredictions.append(np.argmax(prediction))\n",
        "\n",
        "my_submission = pd.DataFrame({'image_id': sample.id, 'class_6': predictions})\n",
        "my_submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Submission file output\n",
        "print(\"Submission File: \\n---------------\\n\")\n",
        "print(my_submission.head()) # Displaying first five predicted output"
      ],
      "metadata": {
        "id": "ndMhDyjAYtHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}